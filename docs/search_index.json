[["index.html", "Portfolio Kjettil Evers 1 Welkom to my portfolio", " Portfolio Kjettil Evers Kjettil Evers 2023-06-06 1 Welkom to my portfolio My name is Kjettil Evers and my portfolio is a representation of all that I’ve learned and accomplished using data science. This portfolio showcases my skills in different subjects using Rmarkdown and more! each chapter contains a exercise that shows how i executed the exercise step by step. It also gives a view it shows the perspective of how I approached my assignments and why I made certain choices. All files in this bookdown are available at my github "],["my-resume.html", "2 My resume", " 2 My resume In the PDF viewer below you can see my resume that I wrote using R. The code that i used to write my resume is available on my github "],["looking-ahead.html", "3 looking ahead 3.1 planning 3.2 final result", " 3 looking ahead This exercise is about what I want to do with my free school time this semester. This is done by answering a few questions. The first question was where I see myself in ~2 years In the next years I will be focusing on my lab and data science experience, but I don’t want to work in the lab my whole life. This is the why I choose to learn data science. Later in life I want to become a senior analist or higher like the head of the lab and work a more communication like job. This is where the data science comes in handy. The skills I acquired will be useful for me to make a good visualization of the data and allow me to communicate this way with the lab and the people I work for. How am I doing now with respect to this goal? currently I’m working in a lab doing viral diagnostics and getting the experiences I need to get higher up. I’m also working on my data science skills by working on my portfolio and doing exercises that help me get better in data science. However because I am still in school, the working part of my goal is at a hold, so for now I will be focusing on data science. What would be the next skill to learn? The next skill I want to learn is to make dashboards with R shiny. Learning to make dashboards in shiny will be useful to achieve my goal I mentioned earlier. A shiny dashboard will be specifically helpful for the communication part of my goal, because it allows me to make a good visualization of the data and communicate this way with other people. 3.1 planning To achieve this goal I made a planning that contains the following steps: First day The first day I will be looking for a good dataset I want to visualize in shiny after finding a dataset I will first make the basic visualizations in Rmarkdown, so I know how I want to visualize it and what it should look like. Below you can find a preview of the first visualization: webshot::webshot(&quot;data/opdracht3_2/test_map.html&quot;, &quot;data/opdracht3_2/test_map.png&quot;) Second day The next step is to start an introduction to R shiny, by watching the following tutorials on youtube: R Shiny Dashboard Project | 1973 USArrests Dashboard for beginners | R Shiny Tutorial for Beginners and How to create interactive maps in R? Leaflet and Mapdeck? I also read the information on https://shiny.posit.co/. Third and fourth day I will be starting on my dashboard for the dataset I found Because of the time limit I will first be making the visualizations and then I will be creating the dashboard it self. The goal is the make the dashboard interactive so you can choose a antibiotic and a year then the dashboard will show you a map of Europe showing Antibiotic usage per country fourth day and fifth day After finishing the dashboard I will make a new tab with additional information about the dataset. At last I will make my shiny dashboard available throug shinyapp.io so it will be easily accessable. 3.2 final result The final result will be available here. The code for the shiny dashboard is available on my github "],["c.-elegans-plate-experiment.html", "4 C. elegans plate experiment", " 4 C. elegans plate experiment In this experiment we will create a dosis response curve from de data provided by J. Louter (INT/ILC). in the experiment adult C.elegans nematodes were exposed to varying concentrations of different compounds. after incubation de number of offspringes where counted. The variables RawData (the outcome - number of offspring counted as an integer value, after incubation time), compName (the generic name of the compound/chemical), the compConcentration (the concentration of the compound), and the expType are the most important variables in this dataset. The first step is to inspect the excel file to see if something stands out. After looking in the excel file I didn’t find anything in particular, so I loaded in the excel file with the following code: CE_LIQ_FLOW&lt;- read_excel(here::here( &quot;data&quot;, &quot;opdracht1&quot;, &quot;CE.LIQ.FLOW.062_Tidydata.xlsx&quot;)) After loading the excel file the first step is to check the datatypes of each columns. CE_LIQ_FLOW ## # A tibble: 360 × 34 ## plateRow plateColumn vialNr dropCode expType expReplicate expName ## &lt;lgl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 NA NA 1 a experiment 3 CE.LIQ.FLOW.062 ## 2 NA NA 1 b experiment 3 CE.LIQ.FLOW.062 ## 3 NA NA 1 c experiment 3 CE.LIQ.FLOW.062 ## 4 NA NA 1 d experiment 3 CE.LIQ.FLOW.062 ## 5 NA NA 1 e experiment 3 CE.LIQ.FLOW.062 ## 6 NA NA 2 a experiment 3 CE.LIQ.FLOW.062 ## 7 NA NA 2 b experiment 3 CE.LIQ.FLOW.062 ## 8 NA NA 2 c experiment 3 CE.LIQ.FLOW.062 ## 9 NA NA 2 d experiment 3 CE.LIQ.FLOW.062 ## 10 NA NA 2 e experiment 3 CE.LIQ.FLOW.062 ## # ℹ 350 more rows ## # ℹ 27 more variables: expDate &lt;dttm&gt;, expResearcher &lt;chr&gt;, expTime &lt;dbl&gt;, ## # expUnit &lt;chr&gt;, expVolumeCounted &lt;dbl&gt;, RawData &lt;dbl&gt;, compCASRN &lt;chr&gt;, ## # compName &lt;chr&gt;, compConcentration &lt;chr&gt;, compUnit &lt;chr&gt;, ## # compDelivery &lt;chr&gt;, compVehicle &lt;chr&gt;, elegansStrain &lt;chr&gt;, ## # elegansInput &lt;dbl&gt;, bacterialStrain &lt;chr&gt;, bacterialTreatment &lt;chr&gt;, ## # bacterialOD600 &lt;dbl&gt;, bacterialConcX &lt;dbl&gt;, bacterialVolume &lt;dbl&gt;, … Here you can see that the compConcentration is out of order. compConcentration is assigned to character data and should be numeric. this can be easily fixed by the follwing code: CE_LIQ_FLOW&lt;- CE_LIQ_FLOW %&gt;% convert(dbl(compConcentration)) The next step is to display the data using a scatterplot. the goal is to show de different compounds and the varying concentrations. I added the compConcentration on the x-axis and the DataRaw counts on the Y-axis. I assigned a colour to each level in compName and a shape to each level in expType. this way the data would be easy to distinguish from each other. ggplot(data = CE_LIQ_FLOW, aes(x = compConcentration, y = RawData)) + geom_point(aes(color = compName, shape = expType), size = 1.5,alpha = 0.8)+ labs(title = &quot;Dose-respons curve C.elegans&quot;, caption = &quot;C.elegans data from J. Louter (INT/ILC)&quot;, y = &quot;number of offspring counted&quot;, x = &quot;compound concentration&quot;) + theme_minimal() As you can see in the plot above the data isn’t showing correctly. this is because the X-axis is not correctly ordered. it goes from 0 to 20 but the compound concentrations are mostly way lower than 5. because of this the data in the graph is not shown correctly. To fix this issue i used the log10 of the compound concentration to normalize the data and get a clear graph. I also added the jitter function so that the data point dont overlap. ggplot(data = CE_LIQ_FLOW, aes(x = log10(compConcentration), y = RawData)) + geom_jitter(aes(color = compName, shape = expType), width = log10(1.3), size = 1.5,alpha = 0.8) + coord_cartesian (xlim =c(-4,2)) + labs(title = &quot;Dose-respons curve C.elegans&quot;, caption = &quot;C.elegans data from J. Louter (INT/ILC)&quot;, y = &quot;number of offspring counted&quot;, x = &quot;log10(compound concentration)&quot;) + theme_minimal() As you can see the data is much clearer now. However I found it usefull to add a line in the graph to easily show the dosis respons curve of the different compounds. ## with line ggplot(data = CE_LIQ_FLOW, aes(x = log10(compConcentration), y = RawData, color = compName, shape = expType)) + geom_smooth(se= FALSE)+ geom_jitter(width = log10(1.3), size = 1.5,alpha = 0.8)+ coord_cartesian (xlim =c(-4,2))+ labs(title = &quot;Dose-respons curve C.elegans&quot;, caption = &quot;C.elegans data from J. Louter (INT/ILC)&quot;, y = &quot;number of offspring counted&quot;, x = &quot;log10(compound concentration)&quot;) + theme_minimal() The positive control for this experiments is ethanol and The negative control for this experiment is S-medium. After visualization the next step would be t analyze the data to see if there is indeed an effect of different concentrations on offspring count and whether the different compounds have a different curve (IC50). I would analyse the data with the following steps: The first step would be to check normality. This is done by an Shapiro-Wilk test. After that Check the variances in the groups. This is done by the Levene’s test. The next step is to do an T-test. In this case i would do an unpaired onesided t-test. this is because the experiment is looking for the IC50 wich means that we assume that de compounds have an inhibitory effect on C.elegans so one sided. For the t-test I would compare each compound separately to the negative controle. By doing this we can determine if there is indeed a significant difference Add last I normalized the data in such a way that the mean value of the negative control (controlNegative) is exactly equal to 1 and all other values are axpressed as an fraction thereof. # Filter for negative control CE_LIQ_FLOW_neg&lt;- CE_LIQ_FLOW %&gt;% filter(expType == &quot;controlNegative&quot; ) # determine average negative control mean(CE_LIQ_FLOW_neg$RawData) ## [1] 85.9 #group and summerize sum_CE_LIQ_FLOW&lt;- CE_LIQ_FLOW %&gt;% group_by(expType, compName, compConcentration ) %&gt;% summarize(mean = mean(RawData, na.rm = TRUE)) sum_CE_LIQ_FLOW ## # A tibble: 22 × 4 ## # Groups: expType, compName [6] ## expType compName compConcentration mean ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 controlNegative S-medium 0 85.9 ## 2 controlPositive Ethanol 1.5 49.4 ## 3 controlVehicleA Ethanol 0.5 91.8 ## 4 experiment 2,6-diisopropylnaphthalene 0.0000499 89.3 ## 5 experiment 2,6-diisopropylnaphthalene 0.000499 83.1 ## 6 experiment 2,6-diisopropylnaphthalene 0.00499 75.1 ## 7 experiment 2,6-diisopropylnaphthalene 0.0499 59 ## 8 experiment 2,6-diisopropylnaphthalene 0.499 43.3 ## 9 experiment 2,6-diisopropylnaphthalene 4.99 40.3 ## 10 experiment decane 0.0000499 89.8 ## # ℹ 12 more rows # plot data and divide y-axis mean by avarage negative controle ggplot(data = sum_CE_LIQ_FLOW, aes(x = log10(compConcentration), y = (mean/85.9))) + geom_jitter(aes(color = compName, shape = expType), width = log10(1.3), size = 3,alpha = 0.8)+ coord_cartesian (xlim =c(-4,2), ylim =c(0,1.2))+ labs(title = &quot;Dose-respons curve C.elegans&quot;, caption = &quot;C.elegans data from J. Louter (INT/ILC)&quot;, y = &quot;average offsprings as fraction \\nof negative control&quot;, x = &quot;log10(compound concentration)&quot;) + theme_minimal() again I made the same plot with a line to easily show the dosis respons curve of the different compounds. ## met line ggplot(data = sum_CE_LIQ_FLOW, aes(x = log10(compConcentration), y = (mean/85.9), color = compName, shape = expType)) + geom_smooth()+ geom_jitter(width = log10(1.3), size = 3,alpha = 0.8)+ coord_cartesian (xlim =c(-4,2), ylim =c(0,1.2))+ labs(title = &quot;Dose-respons curve C.elegans&quot;, caption = &quot;C.elegans data from J. Louter (INT/ILC)&quot;, y = &quot;average offsprings as fraction \\nof negative control&quot;, x = &quot;log10(compound concentration)&quot;) + theme_minimal() By normalizing against the negative control, it is easy to see whether a compound has an effect on the amount of c.elegans. In addition, this is useful because the negative control is “normal” and this should have no effect on the c.elegans. Therefor the negative controle is equal to one. "],["open-peer-review.html", "5 Open Peer Review 5.1 part 1 5.2 Part 2", " 5 Open Peer Review 5.1 part 1 This exercise is about identifying reproducibility issues in a scientific publication. I used the criteria for reproduciblity that are publically available via here I used to following article to grade for reproducibility: Protective Behavior in Course of the COVID-19 Outbreak—Survey Results From Germany Transparency Criteria Definition Response Type Study Purpose A concise statement in the introduction of the article, often in the last paragraph, that establishes the reason the research was conducted. Also called the study objective. yes Data Availability Statement A statement, in an individual section offset from the main body of text, that explains how or if one can access a study’s data. The title of the section may vary, but it must explicitly mention data; it is therefore distinct from a supplementary materials section. yes Data Location Where the article’s data can be accessed, either raw or processed. All in paper or supplementary files Study Location Author has stated in the methods section where the study took place or the data’s country/region of origin. Yes; Germany Author Review The professionalism of the contact information that the author has provided in the manuscript. Tier 2 Ethics Statement A statement within the manuscript indicating any ethical concerns, including the presence of sensitive data. Yes Funding Statement A statement within the manuscript indicating whether or not the authors received funding for their research. No Code Availability Authors have shared access to the most updated code that they used in their study, including code used for analysis. Yes 5.1.1 extra information about the study goal of the study: Disease-related literacy and factors such as age, gender, or education play a major role in shaping individual practices of protective behavior. This paper investigates different types and frequency of practicing protective behaviors, as well as socio-demographic factors that are associated with such behavioral change Method: Data stem from a cross-sectional survey in Germany. Three thousand seven hundred and sixty-five people were contacted, 3,186 participated in the survey. Information on behavior to lower the risk of becoming infected with COVID-19 was assessed by nine items (answer options yes/no). For each item, logistic regression models were used to estimate odds ratios (OR), using education, sex, and age as main predictors and adjusting for partnership status and household composition. results: People with lower educational level were less likely to avoid gatherings (OR = 0.63; 95%CI = 0.48–0.83), adapt their work situation (OR = 0.66; 95%CI = 0.52–0.82), reduce personal contacts and meetings (OR = 0.71; 95%CI = 0.55–0.93), or increase hand hygiene (OR = 0.53; 95%CI = 0.38–0.73). Being female was associated with higher odds of protective behavior for most outcomes. Exceptions were wearing face masks and adapting the own work situation. Associations between respondents’ age and individual behavior change were inconsistent and mostly weak 5.2 Part 2 In this part of the exercise I am going to reproduce at least 1 figure from a article using a data set and R-code shared in the project environment. The first step is to look at the article and code. This research was done in both Turkey and UK. The generalized and pandemic-related anxiety levels, future-oriented consideration, mindfulness, intolerance of uncertainty, risk perception and risk avoidance behaviors of the people who participated in the study were measured. These were then processed in Excel This code loads both data from the UK and Turkey and merges them together so that there is one large excel document containing all relevant data. The merged data is loaded and ggplots are made of the various factors mentioned above. In each ggplot, the correlation of the pandemic-related anxiety levels with one of the factors (generalized anxiety, future-oriented consideration, mindfulness, intolerance of uncertainty, risk perception and risk avoidance behaviors) is visualized. The obtained ggplots are merged into one large figure. After reading the code I would grade it a 4 on a scale from 1 to 5 for readability. I gave it a four because the code is pretty easily to read, However the names of the variables are sometimes confusing. This makes it difficult to distinguish what each plot visualizes After downloading the data and the code I tried running the code. This gave the following error message: Error in relevel.default(data$edu, “below_ug”) : ‘relevel’ only for (unordered) factors To fix this error is change the code from data$edu= relevel(data$edu, “below_ug”) to data$edu= relevel(factor(data$edu), “below_ug”), This is also seen in the code chunk with an comment ## R CODE for Salali, Uysal, Bevan 2021 EMPH anxiety during a pandemic # contact guldeniz.salali@ucl.ac.uk library(lm.beta) rm(list=ls()) ##################################################################### # multiple regressions data= read.csv(&quot;~/dsfb2/dsfb2_workflows_portfolio/opdracht1_2/part2/UK_complete_responses.csv&quot;, header=T) head(data) ## X.1 X GAD.1 GAD.2 GAD.3 GAD.4 GAD.5 GAD.6 GAD.7 FOC.1 FOC.2 FOC.3 FOC.4 FOC.5 ## 1 1 1 4 2 4 3 3 2 1 3 5 2 4 5 ## 2 2 2 2 2 3 3 3 3 2 4 4 4 3 4 ## 3 3 3 2 1 1 1 1 2 2 4 4 4 5 4 ## 4 4 4 2 1 2 1 1 2 1 5 4 4 4 3 ## 5 5 5 2 1 2 2 2 2 2 5 5 5 4 4 ## 6 6 6 1 1 1 2 1 1 1 4 4 4 2 4 ## FOC.6 IUS.1 IUS.2 IUS.3 MAAS.1 MAAS.2 MAAS.3 MAAS.4 MAAS.5 FinancePlan ## 1 2 3 4 2 5 2 5 5 4 8 ## 2 4 4 4 4 2 2 2 4 2 6 ## 3 5 3 5 3 5 3 2 3 4 3 ## 4 5 4 4 1 4 5 4 5 5 6 ## 5 5 4 5 2 3 4 3 5 4 3 ## 6 4 4 2 1 6 4 6 6 6 3 ## MortalityRisk MentalHealth CRA.1 CRA.2 CRA.3 CRA.4 CRA.5 CRA.6 Government ## 1 90 2 1 1 1 1 1 1 2 ## 2 75 1 4 2 1 3 3 2 1 ## 3 100 2 2 1 3 1 2 2 2 ## 4 86 2 2 1 2 3 1 1 2 ## 5 63 1 3 3 1 3 3 4 2 ## 6 99 2 2 1 2 1 1 1 2 ## Norm CurrentBehavior RAB.1 RAB.2 RAB.3 RAB.4 RAB.5 RAB.6 Stockpil ## 1 3 4 4 4 4 4 4 4 4 ## 2 2 4 1 1 1 2 1 1 1 ## 3 3 3 4 4 3 4 1 3 2 ## 4 3 3 1 1 1 2 1 1 1 ## 5 3 5 3 3 2 3 1 3 3 ## 6 3 3 3 3 3 3 1 3 1 ## RiskPerception Vaccine Origin BacktoNormal News Born Gender Country Region ## 1 3 1 1 3 4 9 1 1 12 ## 2 65 1 1 4 5 21 1 1 5 ## 3 31 1 1 4 3 10 1 1 12 ## 4 3 1 2 4 5 18 1 1 12 ## 5 65 1 1 5 3 42 1 1 8 ## 6 100 1 1 5 4 21 2 1 10 ## Education Language Ethnicity Children LiveWith FinancialSatisfaction GAD.mean ## 1 5 4 2 2 2 90 2.714286 ## 2 5 1 5 2 1 95 2.571429 ## 3 5 1 5 2 3 53 1.428571 ## 4 5 5 5 2 2 83 1.428571 ## 5 5 1 5 1 3 82 1.857143 ## 6 4 1 5 1 3 100 1.142857 ## FOC.mean IUS.mean MAAS.mean CRA.mean RAB.mean sex edu origin age ## 1 3.500000 3.000000 4.2 1.000000 4.000000 Female pg natural 25 ## 2 3.833333 4.000000 2.4 2.500000 1.166667 Female pg natural 37 ## 3 4.333333 3.666667 3.4 1.833333 3.166667 Female pg natural 26 ## 4 4.166667 3.000000 4.6 1.666667 1.166667 Female pg artificial 34 ## 5 4.666667 3.666667 3.8 2.833333 2.500000 Female pg natural 58 ## 6 3.666667 2.333333 5.6 1.333333 2.666667 Male ug natural 37 ## vac_hes child news_opposite new_ethnicity new_region origin_binomial ## 1 1 no 3 other south 1 ## 2 1 no 2 white north 1 ## 3 1 no 4 white south 1 ## 4 1 no 2 white south 0 ## 5 1 yes 4 white midlands 1 ## 6 1 yes 3 white south 1 ## new_back_normal new_finance_plan ## 1 less6months 0 ## 2 6to12months 6 ## 3 6to12months 3 ## 4 6to12months 6 ## 5 more12months 3 ## 6 more12months 3 colnames(data) ## [1] &quot;X.1&quot; &quot;X&quot; &quot;GAD.1&quot; ## [4] &quot;GAD.2&quot; &quot;GAD.3&quot; &quot;GAD.4&quot; ## [7] &quot;GAD.5&quot; &quot;GAD.6&quot; &quot;GAD.7&quot; ## [10] &quot;FOC.1&quot; &quot;FOC.2&quot; &quot;FOC.3&quot; ## [13] &quot;FOC.4&quot; &quot;FOC.5&quot; &quot;FOC.6&quot; ## [16] &quot;IUS.1&quot; &quot;IUS.2&quot; &quot;IUS.3&quot; ## [19] &quot;MAAS.1&quot; &quot;MAAS.2&quot; &quot;MAAS.3&quot; ## [22] &quot;MAAS.4&quot; &quot;MAAS.5&quot; &quot;FinancePlan&quot; ## [25] &quot;MortalityRisk&quot; &quot;MentalHealth&quot; &quot;CRA.1&quot; ## [28] &quot;CRA.2&quot; &quot;CRA.3&quot; &quot;CRA.4&quot; ## [31] &quot;CRA.5&quot; &quot;CRA.6&quot; &quot;Government&quot; ## [34] &quot;Norm&quot; &quot;CurrentBehavior&quot; &quot;RAB.1&quot; ## [37] &quot;RAB.2&quot; &quot;RAB.3&quot; &quot;RAB.4&quot; ## [40] &quot;RAB.5&quot; &quot;RAB.6&quot; &quot;Stockpil&quot; ## [43] &quot;RiskPerception&quot; &quot;Vaccine&quot; &quot;Origin&quot; ## [46] &quot;BacktoNormal&quot; &quot;News&quot; &quot;Born&quot; ## [49] &quot;Gender&quot; &quot;Country&quot; &quot;Region&quot; ## [52] &quot;Education&quot; &quot;Language&quot; &quot;Ethnicity&quot; ## [55] &quot;Children&quot; &quot;LiveWith&quot; &quot;FinancialSatisfaction&quot; ## [58] &quot;GAD.mean&quot; &quot;FOC.mean&quot; &quot;IUS.mean&quot; ## [61] &quot;MAAS.mean&quot; &quot;CRA.mean&quot; &quot;RAB.mean&quot; ## [64] &quot;sex&quot; &quot;edu&quot; &quot;origin&quot; ## [67] &quot;age&quot; &quot;vac_hes&quot; &quot;child&quot; ## [70] &quot;news_opposite&quot; &quot;new_ethnicity&quot; &quot;new_region&quot; ## [73] &quot;origin_binomial&quot; &quot;new_back_normal&quot; &quot;new_finance_plan&quot; data_UK= data levels(data$edu) ## NULL # here I changed the code data$edu= relevel(factor(data$edu), &quot;below_ug&quot;) GAD_UK_m1= lm(GAD.mean ~ IUS.mean + FOC.mean + MAAS.mean + RiskPerception + + edu + age + sex + FinancialSatisfaction, data=data) summary(GAD_UK_m1) ## ## Call: ## lm(formula = GAD.mean ~ IUS.mean + FOC.mean + MAAS.mean + RiskPerception + ## +edu + age + sex + FinancialSatisfaction, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.54566 -0.39809 -0.06166 0.29798 2.07401 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.3799447 0.1686523 14.112 &lt; 2e-16 *** ## IUS.mean 0.2357630 0.0212287 11.106 &lt; 2e-16 *** ## FOC.mean 0.0416286 0.0238279 1.747 0.080913 . ## MAAS.mean -0.1840365 0.0228474 -8.055 2.09e-15 *** ## RiskPerception 0.0012596 0.0007488 1.682 0.092843 . ## edupg -0.1613494 0.0480636 -3.357 0.000815 *** ## eduug -0.1928974 0.0454271 -4.246 2.36e-05 *** ## age -0.0048906 0.0013765 -3.553 0.000398 *** ## sexMale -0.1008582 0.0397809 -2.535 0.011374 * ## sexOther 0.1336953 0.1054567 1.268 0.205153 ## FinancialSatisfaction -0.0050923 0.0007260 -7.014 4.07e-12 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5713 on 1077 degrees of freedom ## Multiple R-squared: 0.3963, Adjusted R-squared: 0.3907 ## F-statistic: 70.7 on 10 and 1077 DF, p-value: &lt; 2.2e-16 # Covid-related anxiety model UK (CRA.mean) CRA_UK_full= lm(CRA.mean ~ IUS.mean + FOC.mean + MAAS.mean + RiskPerception + edu + age + sex + FinancialSatisfaction, data= data) summary(CRA_UK_full) ## ## Call: ## lm(formula = CRA.mean ~ IUS.mean + FOC.mean + MAAS.mean + RiskPerception + ## edu + age + sex + FinancialSatisfaction, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.87517 -0.40815 0.00299 0.38831 1.69314 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.6017998 0.1659693 15.676 &lt; 2e-16 *** ## IUS.mean 0.1631601 0.0208910 7.810 1.35e-14 *** ## FOC.mean 0.0554364 0.0234488 2.364 0.018249 * ## MAAS.mean -0.1517579 0.0224840 -6.750 2.42e-11 *** ## RiskPerception 0.0040031 0.0007369 5.432 6.88e-08 *** ## edupg -0.2076348 0.0472989 -4.390 1.25e-05 *** ## eduug -0.1651907 0.0447045 -3.695 0.000231 *** ## age 0.0017242 0.0013546 1.273 0.203354 ## sexMale -0.1451059 0.0391481 -3.707 0.000221 *** ## sexOther -0.0259214 0.1037791 -0.250 0.802809 ## FinancialSatisfaction -0.0064910 0.0007144 -9.086 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5622 on 1077 degrees of freedom ## Multiple R-squared: 0.3216, Adjusted R-squared: 0.3153 ## F-statistic: 51.07 on 10 and 1077 DF, p-value: &lt; 2.2e-16 lm.beta(CRA_UK_full) # standardized coefficients ## ## Call: ## lm(formula = CRA.mean ~ IUS.mean + FOC.mean + MAAS.mean + RiskPerception + ## edu + age + sex + FinancialSatisfaction, data = data) ## ## Standardized Coefficients:: ## (Intercept) IUS.mean FOC.mean ## NA 0.243744552 0.062843200 ## MAAS.mean RiskPerception edupg ## -0.204857719 0.138432288 -0.145841019 ## eduug age sexMale ## -0.119459402 0.034775472 -0.097529229 ## sexOther FinancialSatisfaction ## -0.006350153 -0.237989055 # Risk avoidance behaviour RAB UK RAB_UK= lm(RAB.mean ~ IUS.mean + MAAS.mean + CRA.mean + RiskPerception +FinancialSatisfaction + age + sex + edu, data=data) # just anxiety RAB_UK_1= lm(RAB.mean ~ CRA.mean, data=data) summary(RAB_UK) ## ## Call: ## lm(formula = RAB.mean ~ IUS.mean + MAAS.mean + CRA.mean + RiskPerception + ## FinancialSatisfaction + age + sex + edu, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.0625 -0.6589 0.1295 0.6633 2.1089 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.7455072 0.2491171 7.007 4.29e-12 *** ## IUS.mean -0.0781474 0.0303889 -2.572 0.010257 * ## MAAS.mean 0.0791132 0.0325364 2.432 0.015198 * ## CRA.mean 0.3296142 0.0432463 7.622 5.47e-14 *** ## RiskPerception 0.0007395 0.0010629 0.696 0.486720 ## FinancialSatisfaction -0.0023526 0.0010473 -2.246 0.024883 * ## age 0.0070323 0.0019226 3.658 0.000267 *** ## sexMale -0.1258016 0.0560258 -2.245 0.024943 * ## sexOther -0.1807633 0.1476739 -1.224 0.221193 ## edupg -0.2481045 0.0652443 -3.803 0.000151 *** ## eduug -0.2460540 0.0633249 -3.886 0.000108 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.8 on 1077 degrees of freedom ## Multiple R-squared: 0.1129, Adjusted R-squared: 0.1046 ## F-statistic: 13.7 on 10 and 1077 DF, p-value: &lt; 2.2e-16 summary(RAB_UK_1) ## ## Call: ## lm(formula = RAB.mean ~ CRA.mean, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.8275 -0.7358 0.1312 0.7184 1.8147 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.91010 0.09029 21.156 &lt; 2e-16 *** ## CRA.mean 0.27522 0.03682 7.474 1.59e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.8249 on 1086 degrees of freedom ## Multiple R-squared: 0.04892, Adjusted R-squared: 0.04805 ## F-statistic: 55.86 on 1 and 1086 DF, p-value: 1.595e-13 library(lm.beta) lm.beta(RAB_UK) ## ## Call: ## lm(formula = RAB.mean ~ IUS.mean + MAAS.mean + CRA.mean + RiskPerception + ## FinancialSatisfaction + age + sex + edu, data = data) ## ## Standardized Coefficients:: ## (Intercept) IUS.mean MAAS.mean ## NA -0.09382526 0.08582896 ## CRA.mean RiskPerception FinancialSatisfaction ## 0.26490491 0.02055262 -0.06932354 ## age sexMale sexOther ## 0.11399114 -0.06795476 -0.03558935 ## edupg eduug ## -0.14005491 -0.14300437 ############################################ # TR data= read.csv(&quot;~/dsfb2/dsfb2_workflows_portfolio/opdracht1_2/part2/TR_complete_responses.csv&quot;, header=T) head(data) ## X.1 X GAD.1 GAD.2 GAD.3 GAD.4 GAD.5 GAD.6 GAD.7 FOC.1 FOC.2 FOC.3 FOC.4 FOC.5 ## 1 1 1 2 2 2 2 2 2 2 3 4 3 2 2 ## 2 2 2 2 3 3 2 1 2 2 3 2 2 4 2 ## 3 3 3 2 1 2 2 2 3 3 4 3 4 4 4 ## 4 4 4 4 4 4 4 4 4 3 5 5 4 3 4 ## 5 5 5 2 2 2 2 1 3 1 4 4 4 3 3 ## 6 6 6 2 2 2 4 1 3 1 3 3 3 4 4 ## FOC.6 IUS.1 IUS.2 IUS.3 MAAS.1 MAAS.2 MAAS.3 MAAS.4 MAAS.5 FinancePlan ## 1 3 4 5 5 2 3 4 3 2 4 ## 2 2 2 4 1 4 3 5 3 3 2 ## 3 4 4 4 4 4 4 5 5 3 2 ## 4 5 5 5 5 6 6 3 1 2 5 ## 5 4 1 4 4 5 3 4 3 3 1 ## 6 4 1 4 3 6 6 6 3 2 1 ## MortalityRisk MentalHealth CRA.1 CRA.2 CRA.3 CRA.4 CRA.5 CRA.6 Government ## 1 20 2 4 3 4 4 4 3 1 ## 2 75 2 4 3 2 3 3 4 2 ## 3 67 2 4 4 1 4 3 4 1 ## 4 74 1 4 2 1 4 3 4 1 ## 5 40 2 3 2 4 4 1 4 1 ## 6 69 2 3 1 1 1 1 1 3 ## Norm CurrentBehavior RAB.1 RAB.2 RAB.3 RAB.4 RAB.5 RAB.6 Stockpil ## 1 2 3 4 3 4 4 4 4 3 ## 2 1 3 4 3 4 4 4 4 3 ## 3 2 4 4 4 4 4 4 4 3 ## 4 1 5 4 4 4 4 1 4 4 ## 5 1 3 4 3 4 4 1 4 2 ## 6 3 5 2 1 1 4 1 3 1 ## RiskPerception Vaccine Origin BacktoNormal News Born Gender Country Region ## 1 90 1 1 5 5 21 1 1 2 ## 2 54 1 2 5 3 12 1 1 3 ## 3 56 3 1 5 3 13 1 1 4 ## 4 53 1 1 0 1 4 1 1 4 ## 5 60 2 3 5 4 12 2 1 4 ## 6 5 1 1 5 3 7 1 1 56 ## Education Language Children LiveWith FinancialSatisfaction GAD.mean FOC.mean ## 1 4 1 2 2 35 2.000000 2.833333 ## 2 5 2 2 3 67 2.142857 2.500000 ## 3 5 1 2 3 5 2.142857 3.833333 ## 4 3 2 2 3 71 3.857143 4.333333 ## 5 4 1 2 3 30 1.857143 3.666667 ## 6 4 1 2 3 0 2.142857 3.500000 ## IUS.mean MAAS.mean CRA.mean RAB.mean sex edu origin ## 1 4.666667 2.8 3.666667 3.833333 Female ug natural ## 2 2.333333 3.6 3.166667 3.833333 Female pg artificial ## 3 4.000000 4.2 3.333333 4.000000 Female pg natural ## 4 5.000000 3.6 3.000000 3.500000 Female below_ug natural ## 5 3.000000 3.6 3.000000 3.333333 Male ug not_sure ## 6 2.666667 4.6 1.333333 2.000000 Female ug natural ## origin_binomial age vac_hes child news_opposite new_region new_back_normal ## 1 1 37 1 no 2 istanbul more12months ## 2 0 28 1 no 4 ankara more12months ## 3 1 29 0 no 4 izmir more12months ## 4 1 20 1 no 6 izmir other ## 5 0 28 0 no 3 izmir more12months ## 6 1 23 1 no 4 other more12months ## new_finance_plan ## 1 4 ## 2 2 ## 3 2 ## 4 5 ## 5 1 ## 6 1 colnames(data) ## [1] &quot;X.1&quot; &quot;X&quot; &quot;GAD.1&quot; ## [4] &quot;GAD.2&quot; &quot;GAD.3&quot; &quot;GAD.4&quot; ## [7] &quot;GAD.5&quot; &quot;GAD.6&quot; &quot;GAD.7&quot; ## [10] &quot;FOC.1&quot; &quot;FOC.2&quot; &quot;FOC.3&quot; ## [13] &quot;FOC.4&quot; &quot;FOC.5&quot; &quot;FOC.6&quot; ## [16] &quot;IUS.1&quot; &quot;IUS.2&quot; &quot;IUS.3&quot; ## [19] &quot;MAAS.1&quot; &quot;MAAS.2&quot; &quot;MAAS.3&quot; ## [22] &quot;MAAS.4&quot; &quot;MAAS.5&quot; &quot;FinancePlan&quot; ## [25] &quot;MortalityRisk&quot; &quot;MentalHealth&quot; &quot;CRA.1&quot; ## [28] &quot;CRA.2&quot; &quot;CRA.3&quot; &quot;CRA.4&quot; ## [31] &quot;CRA.5&quot; &quot;CRA.6&quot; &quot;Government&quot; ## [34] &quot;Norm&quot; &quot;CurrentBehavior&quot; &quot;RAB.1&quot; ## [37] &quot;RAB.2&quot; &quot;RAB.3&quot; &quot;RAB.4&quot; ## [40] &quot;RAB.5&quot; &quot;RAB.6&quot; &quot;Stockpil&quot; ## [43] &quot;RiskPerception&quot; &quot;Vaccine&quot; &quot;Origin&quot; ## [46] &quot;BacktoNormal&quot; &quot;News&quot; &quot;Born&quot; ## [49] &quot;Gender&quot; &quot;Country&quot; &quot;Region&quot; ## [52] &quot;Education&quot; &quot;Language&quot; &quot;Children&quot; ## [55] &quot;LiveWith&quot; &quot;FinancialSatisfaction&quot; &quot;GAD.mean&quot; ## [58] &quot;FOC.mean&quot; &quot;IUS.mean&quot; &quot;MAAS.mean&quot; ## [61] &quot;CRA.mean&quot; &quot;RAB.mean&quot; &quot;sex&quot; ## [64] &quot;edu&quot; &quot;origin&quot; &quot;origin_binomial&quot; ## [67] &quot;age&quot; &quot;vac_hes&quot; &quot;child&quot; ## [70] &quot;news_opposite&quot; &quot;new_region&quot; &quot;new_back_normal&quot; ## [73] &quot;new_finance_plan&quot; summary(data$edu) ## Length Class Mode ## 3936 character character summary(data$age) # someone with 103 ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 18.0 23.0 29.0 31.9 38.0 103.0 data_TR= data[-which(data$age&gt;=90),] # omit 103 yo # Covid-related anxiety model TR (CRA.mean) CRA_TR_full= lm(CRA.mean ~ IUS.mean + FOC.mean + MAAS.mean + RiskPerception + edu + age + sex + FinancialSatisfaction, data= data) summary(CRA_TR_full) ## ## Call: ## lm(formula = CRA.mean ~ IUS.mean + FOC.mean + MAAS.mean + RiskPerception + ## edu + age + sex + FinancialSatisfaction, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.07771 -0.35942 0.05142 0.41199 1.59805 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.3035527 0.0852878 27.009 &lt; 2e-16 *** ## IUS.mean 0.2096651 0.0112248 18.679 &lt; 2e-16 *** ## FOC.mean 0.0918695 0.0141743 6.481 1.02e-10 *** ## MAAS.mean -0.0781558 0.0119077 -6.563 5.94e-11 *** ## RiskPerception 0.0042261 0.0003567 11.849 &lt; 2e-16 *** ## edupg -0.0056260 0.0301494 -0.187 0.8520 ## eduug 0.0499010 0.0229440 2.175 0.0297 * ## age -0.0050471 0.0009243 -5.461 5.04e-08 *** ## sexMale -0.2287054 0.0193984 -11.790 &lt; 2e-16 *** ## sexOther -0.0387516 0.0999543 -0.388 0.6983 ## FinancialSatisfaction -0.0035692 0.0003330 -10.718 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5698 on 3925 degrees of freedom ## Multiple R-squared: 0.2889, Adjusted R-squared: 0.2871 ## F-statistic: 159.5 on 10 and 3925 DF, p-value: &lt; 2.2e-16 lm.beta(CRA_TR_full) ## ## Call: ## lm(formula = CRA.mean ~ IUS.mean + FOC.mean + MAAS.mean + RiskPerception + ## edu + age + sex + FinancialSatisfaction, data = data) ## ## Standardized Coefficients:: ## (Intercept) IUS.mean FOC.mean ## NA 0.288424131 0.088656008 ## MAAS.mean RiskPerception edupg ## -0.099132303 0.161941494 -0.003166402 ## eduug age sexMale ## 0.036866823 -0.084319199 -0.163671156 ## sexOther FinancialSatisfaction ## -0.005236145 -0.149411495 # Risk avoidance behaviour RAB TR RAB_TR= lm(RAB.mean ~ IUS.mean + MAAS.mean + CRA.mean + RiskPerception +FinancialSatisfaction + age + sex + edu, data=data) RAB_TR_1= lm(RAB.mean ~ CRA.mean, data=data) summary(RAB_TR) ## ## Call: ## lm(formula = RAB.mean ~ IUS.mean + MAAS.mean + CRA.mean + RiskPerception + ## FinancialSatisfaction + age + sex + edu, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.5839 -0.2271 0.1646 0.3870 1.0963 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.7818104 0.0870500 31.956 &lt; 2e-16 *** ## IUS.mean -0.0433844 0.0117128 -3.704 0.000215 *** ## MAAS.mean 0.0258884 0.0120021 2.157 0.031067 * ## CRA.mean 0.2228882 0.0159654 13.961 &lt; 2e-16 *** ## RiskPerception -0.0014377 0.0003649 -3.939 8.31e-05 *** ## FinancialSatisfaction -0.0003284 0.0003385 -0.970 0.331986 ## age 0.0059804 0.0009329 6.410 1.62e-10 *** ## sexMale -0.1527703 0.0198326 -7.703 1.67e-14 *** ## sexOther -0.1424848 0.1005122 -1.418 0.156391 ## edupg 0.0530643 0.0302441 1.755 0.079417 . ## eduug 0.0721934 0.0230811 3.128 0.001774 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.573 on 3925 degrees of freedom ## Multiple R-squared: 0.08512, Adjusted R-squared: 0.08279 ## F-statistic: 36.52 on 10 and 3925 DF, p-value: &lt; 2.2e-16 summary(RAB_TR_1) ## ## Call: ## lm(formula = RAB.mean ~ CRA.mean, data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.5724 -0.2390 0.1741 0.4150 0.8898 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.92537 0.04109 71.20 &lt;2e-16 *** ## CRA.mean 0.18485 0.01382 13.37 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5852 on 3934 degrees of freedom ## Multiple R-squared: 0.04348, Adjusted R-squared: 0.04324 ## F-statistic: 178.8 on 1 and 3934 DF, p-value: &lt; 2.2e-16 lm.beta(RAB_TR) ## ## Call: ## lm(formula = RAB.mean ~ IUS.mean + MAAS.mean + CRA.mean + RiskPerception + ## FinancialSatisfaction + age + sex + edu, data = data) ## ## Standardized Coefficients:: ## (Intercept) IUS.mean MAAS.mean ## NA -0.06732190 0.03704047 ## CRA.mean RiskPerception FinancialSatisfaction ## 0.25142284 -0.06214483 -0.01550873 ## age sexMale sexOther ## 0.11270365 -0.12332532 -0.02171744 ## edupg eduug ## 0.03368905 0.06016466 ############PLOTS FOR ANXIETY ### #library(ggplot2) #choose which data #data= data_UK1 #data= data_TR1 #colnames(data_UK1) #colnames(data_TR1) #dataUKmerge= data_UK1[,c(&quot;RAB.mean&quot;,&quot;GAD.mean&quot;, &quot;GAD.Total.Adj&quot;, &quot;CRA.mean&quot;,&quot;FOC.mean&quot;, # &quot;IUS.mean&quot;, &quot;MAAS.mean&quot;, &quot;RiskPerception&quot;, # &quot;FinancialSatisfaction&quot;, &quot;age&quot;, &quot;sex&quot;, &quot;edu&quot;)] #dataTRmerge= data_TR1[,c(&quot;RAB.mean&quot;,&quot;GAD.mean&quot;, &quot;GAD.Total.Adj&quot;, &quot;CRA.mean&quot;,&quot;FOC.mean&quot;, # &quot;IUS.mean&quot;, &quot;MAAS.mean&quot;, &quot;RiskPerception&quot;, # &quot;FinancialSatisfaction&quot;, &quot;age&quot;, &quot;sex&quot;, &quot;edu&quot;)] #dataTRmerge$Country=rep(&quot;Turkey&quot;, length(dataTRmerge[,1])) #dataUKmerge$Country=rep(&quot;UK&quot;, length(dataUKmerge[,1])) #datamerge= rbind(dataTRmerge, dataUKmerge) #write.csv(datamerge, &quot;combineddata.csv&quot;) ## READ FROM HERE: TR UK combined regression analysis datamerge= read.csv(&quot;~/dsfb2/dsfb2_workflows_portfolio/opdracht1_2/part2/combineddata.csv&quot;) head(datamerge) ## X RAB.mean GAD.mean GAD.Total.Adj CRA.mean FOC.mean IUS.mean MAAS.mean ## 1 1 3.833333 2.000000 7 3.666667 2.833333 4.666667 2.8 ## 2 2 3.833333 2.142857 8 3.166667 2.500000 2.333333 3.6 ## 3 3 4.000000 2.142857 8 3.333333 3.833333 4.000000 4.2 ## 4 4 3.500000 3.857143 20 3.000000 4.333333 5.000000 3.6 ## 5 5 3.333333 1.857143 6 3.000000 3.666667 3.000000 3.6 ## 6 6 2.000000 2.142857 8 1.333333 3.500000 2.666667 4.6 ## RiskPerception FinancialSatisfaction age sex edu Country ## 1 90 35 37 1 3 Turkey ## 2 54 67 28 1 2 Turkey ## 3 56 5 29 1 2 Turkey ## 4 53 71 20 1 1 Turkey ## 5 60 30 28 2 3 Turkey ## 6 5 0 23 1 3 Turkey summary(datamerge$Country) ## Length Class Mode ## 5023 character character library(ggplot2) s= 8 p=1 t=0.3 gad.cra= ggplot(datamerge, aes(x=GAD.mean, y=CRA.mean, color=Country)) + # geom_point(alpha = 0.3) + # with alpha blending to make points transparent geom_jitter(size=t) + geom_point(size=t) + geom_smooth(method=lm, se=T, size=p) + # or method=loess ylab(&quot;Pandemic anxiety&quot;) + xlab(&quot;Generalized anxiety&quot;) + theme(axis.title=element_text(size=s)) + theme(legend.position = &quot;none&quot;) ## Warning: Using `size` aesthetic for lines was ## deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. ## This warning is displayed once every 8 ## hours. ## Call ## `lifecycle::last_lifecycle_warnings()` ## to see where this warning was ## generated. gad.ius= ggplot(datamerge, aes(x=IUS.mean, y=GAD.Total.Adj, color=Country)) + # geom_point(alpha = 0.3) + geom_jitter(size=t) + geom_point(size=t) + geom_smooth(method=lm, se=T, size=p) + # or method=loess ylab(&quot;GAD-7&quot;) + xlab(&quot;Intolerance of uncertainty&quot;) + theme(axis.title=element_text(size=s)) + theme(legend.position = &quot;none&quot;) cra.ius= ggplot(datamerge, aes(x=IUS.mean, y=CRA.mean, color=Country)) + #geom_point(alpha = 0.3) + geom_jitter(size=t) + geom_point(size=t) + geom_smooth(method=lm, se=T, size=p) + # or method=loess ylab(&quot;Pandemic anxiety&quot;) + xlab(&quot;Intolerance of uncertainty&quot;) + theme(axis.title=element_text(size=s)) + theme(legend.position = &quot;none&quot;) #ylim(1.5,3.5) cra.maas= ggplot(datamerge, aes(x=MAAS.mean, y=CRA.mean, color=Country)) + #geom_point(alpha = 0.3) + geom_jitter(size=t) + geom_point(size=t) + geom_smooth(method=lm, se=T, size=p) + # or method=loess ylab(&quot;Pandemic anxiety&quot;) + ylab(&quot;Pandemic anxiety&quot;) + xlab(&quot;Mindfulness&quot;) + theme(axis.title=element_text(size=s)) + theme(legend.position = &quot;none&quot;) cra.foc= ggplot(datamerge, aes(x=FOC.mean, y=CRA.mean, color=Country)) + #geom_point(alpha = 0.3) + geom_jitter(size=t) + geom_point(size=t) + geom_smooth(method=lm, se=T, size=p) + # or method=loess ylab(&quot;Pandemic anxiety&quot;) + xlab(&quot;Future orientation&quot;) + theme(axis.title=element_text(size=s)) + theme(legend.position = &quot;none&quot;) cra.risk= ggplot(datamerge, aes(x=RiskPerception, y=CRA.mean, color=Country)) + #geom_point(alpha = 0.3) + geom_jitter(size=t) + geom_point(size=t) + geom_smooth(method=lm, se=T, size=p) + # or method=loess ylab(&quot;Pandemic anxiety&quot;) + xlab(&quot;Risk Perception&quot;) + theme(axis.title=element_text(size=s)) + theme(legend.position = &quot;none&quot;) rab.cra= ggplot(datamerge, aes(x=CRA.mean, y=RAB.mean, color=Country)) + #geom_point(alpha = 0.3) + geom_jitter(size=t) + geom_point(size=t) + geom_smooth(method=lm, se=T, size=p) + # or method=loess ylab(&quot;Risk avoidance behaviour&quot;) + ylab(&quot;Risk avoidance behaviour&quot;) + xlab(&quot;Pandemic anxiety&quot;) + theme(axis.title=element_text(size=s)) + theme(legend.position = &quot;none&quot;) rab.gad= ggplot(datamerge, aes(x=GAD.mean, y=RAB.mean, color=Country)) + # geom_point(alpha = 0.3) + geom_jitter(size=t) + geom_point(size=t) + geom_smooth(method=lm, se=T, size=p) + # or method=loess ylab(&quot;Risk avoidance behaviour&quot;) + ylab(&quot;Risk avoidance behaviour&quot;) + xlab(&quot;Generalized anxiety&quot;) + theme(axis.title=element_text(size=s)) + theme(legend.position = &quot;none&quot;) library(ggpubr) ggarrange(gad.cra, cra.foc, cra.ius, cra.maas, cra.risk, rab.cra, labels = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;), ncol = 2, nrow = 3, font.label = list(size = 10, color = &quot;black&quot;, face = &quot;bold&quot;, family = NULL)) ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## `geom_smooth()` using formula = &#39;y ~ x&#39; on a scale from 1 (very hard) to 5 (very easy), I would grade this article a 4 for how hard is was to reproduce the visualization from the article. I gave it a four because is was pretty easy to reproduce the graph. However I had to download the data wich made is easy for me to the load the data. It would be better if the code contained an URL to load the data. This would increase the reproducibility "],["example-guerrilla-analytics-structure.html", "6 example guerrilla analytics structure", " 6 example guerrilla analytics structure In this exercise we will show my folder structure using the guerrilla analytics structure fs::dir_tree(here::here(&quot;data&quot;, &quot;opdracht2&quot;)) ## C:/Users/kjett/OneDrive - Stichting Hogeschool Utrecht/Documenten/dsfb2/kjettil.github.io/data/opdracht2 ## ├── metagenomics ## │ ├── data ## │ │ └── README.txt ## │ ├── README.txt ## │ ├── report ## │ │ ├── metagenomics.html ## │ │ └── metagenomics.Rmd ## │ ├── results ## │ │ ├── bracken ## │ │ │ ├── mock1.bracken ## │ │ │ └── mock2.bracken ## │ │ ├── fastqc ## │ │ │ ├── HU1_MOCK1_L001_R1_001_fastqc.html ## │ │ │ ├── HU1_MOCK1_L001_R1_001_fastqc.zip ## │ │ │ ├── HU1_MOCK1_L001_R2_001_fastqc.html ## │ │ │ ├── HU1_MOCK1_L001_R2_001_fastqc.zip ## │ │ │ ├── HU2_MOCK2_L001_R1_001_fastqc.html ## │ │ │ ├── HU2_MOCK2_L001_R1_001_fastqc.zip ## │ │ │ ├── HU2_MOCK2_L001_R2_001_fastqc.html ## │ │ │ └── HU2_MOCK2_L001_R2_001_fastqc.zip ## │ │ ├── images ## │ │ │ ├── fastqc_mock1_R1_per_base_quality.png ## │ │ │ ├── fastqc_mock1_R2_per_base_quality.png ## │ │ │ ├── fastqc_mock2_R1_per_base_quality.png ## │ │ │ ├── fastqc_mock2_R2_per_base_quality.png ## │ │ │ └── README.txt ## │ │ ├── kraken2 ## │ │ │ ├── mock1 ## │ │ │ │ ├── mock1.report ## │ │ │ │ ├── mock1_bracken_species.biom ## │ │ │ │ └── mock1_bracken_species.report ## │ │ │ └── mock2 ## │ │ │ ├── mock2.report ## │ │ │ ├── mock2_bracken_species.biom ## │ │ │ └── mock2_bracken_species.report ## │ │ └── README ## │ └── setup_meta_env.yml ## └── rna_sequencing ## ├── rnaseq_formatieve_opdracht ## │ ├── data ## │ │ └── README.txt ## │ ├── README.txt ## │ ├── report ## │ │ ├── formatieve_opdracht1.html ## │ │ └── formatieve_opdracht1.Rmd ## │ └── results ## │ ├── bamfiles ## │ └── counts ## └── rnaseq_toetsopdracht ## ├── data ## │ ├── metadata ## │ │ ├── onecut_sampledata_OC3.csv ## │ │ └── onecut_sampledata_OC3.md5 ## │ ├── README.txt ## │ ├── SRR7866699_1.fastq.gz ## │ ├── SRR7866699_2.fastq.gz ## │ ├── SRR7866705_1.fastq.gz ## │ └── SRR7866705_2.fastq.gz ## ├── README.txt ## ├── report ## │ ├── toetsopdracht.html ## │ └── toetsopdracht.Rmd ## └── results ## ├── counts ## ├── images ## │ ├── fastqc_SRR7866699_1_per_base_quality.png ## │ ├── fastqc_SRR7866699_1_per_sequence_quality.png ## │ ├── fastqc_SRR7866699_2_per_base_quality.png ## │ ├── fastqc_SRR7866699_2_per_sequence_quality.png ## │ ├── fastqc_SRR7866705_1_per_base_quality.png ## │ ├── fastqc_SRR7866705_2_per_base_quality.png ## │ └── README.txt ## └── README.txt "],["rmarkdown-parameterization.html", "7 RMarkdown parameterization 7.1 preview parameterized Rmarkdown covid cases and deaths 7.2 testing parameters 7.3 results", " 7 RMarkdown parameterization The aim of this assignment is to create an RMardown file containing a parameterized report for the COVID-19 cases as can be downloaded from the ECDC. The Rmd should include at least three parameters: The country to which the report applies to The year that the reported data applies to The period in months that the report applies to 7.1 preview parameterized Rmarkdown covid cases and deaths I created a parameterized Rmarkdown as seen below. The parameterized Rmarkdown is available via github using webshot I created a screenshot of the parameterized Rmarkdown HTML I made, so it would be easier to preview this excercise in github pages. As seen in the parameterized Rmarkdown the default is set to france august 2020 #make screenshot of parameterized Rmarkdown webshot::webshot(&quot;data/opdracht9/portfolio9.html&quot;, &quot;data/opdracht9/portfolio9.png&quot;) 7.2 testing parameters The next step is to test the parameterized Rmarkdown by using rmarkdown::render() and setting params of choice. I named the output file the same as the param settings so that a HTML will be called like the parameters i set. rmarkdown::render(&quot;data/opdracht9/portfolio9.Rmd&quot;, params = list(country = &quot;Germany&quot;, year = 2021, month = 5), output_file = &quot;germany_2021_05&quot;) ## 1/11 ## 2/11 [libraries] ## 3/11 ## 4/11 [loading data] ## 5/11 ## 6/11 [make dataset usable] ## 7/11 ## 8/11 [ggplot covid cases] ## 9/11 ## 10/11 [covid deaths] ## 11/11 ## &quot;C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/pandoc&quot; +RTS -K512m -RTS portfolio9.knit.md --to html4 --from markdown+autolink_bare_uris+tex_math_single_backslash --output germany_2021_05.html --lua-filter &quot;C:\\Users\\kjett\\AppData\\Local\\R\\win-library\\4.2\\rmarkdown\\rmarkdown\\lua\\pagebreak.lua&quot; --lua-filter &quot;C:\\Users\\kjett\\AppData\\Local\\R\\win-library\\4.2\\rmarkdown\\rmarkdown\\lua\\latex-div.lua&quot; --embed-resources --standalone --variable bs3=TRUE --section-divs --template &quot;C:\\Users\\kjett\\AppData\\Local\\R\\win-library\\4.2\\rmarkdown\\rmd\\h\\default.html&quot; --no-highlight --variable highlightjs=1 --variable theme=bootstrap --mathjax --variable &quot;mathjax-url=https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; --include-in-header &quot;C:\\Users\\kjett\\AppData\\Local\\Temp\\RtmpSkEun0\\rmarkdown-str21804b757ebc.html&quot; 7.3 results The last step is to make show the HTML using webshot to see that the parameters work webshot::webshot(&quot;data/opdracht9/germany_2021_05.html&quot;, &quot;data/opdracht9/germany_2021_05.png&quot;) After checking the results you can see that the paramaters work and can be used for other countrys and dates. "],["relational-databases.html", "8 relational databases 8.1 The data 8.2 inspecting merged data 8.3 visualization", " 8 relational databases In this exercise I will be using a relational database. this is a type of database that stores and provides access to data points that are related to one another. I will be using DBeaver to combine the Gapminder dataset with 2 other datasets containing flu/dengue google searches per country over the years. I used the following libraries for this exercise: library(png) library(grid) library(gridExtra) library(DBI) library(tidyverse) library(readxl) library(readr) library(dslabs) library(tidyverse) library(hablar) library(DBI) library(RPostgreSQL) 8.1 The data The first step is to load and inspect the Flu (./data/flu_data.csv), dengue (“./data/dengue_data.csv) and gapminder data ({dslabs} package) available here flu_data &lt;- read_csv(&quot;https://raw.githubusercontent.com/DataScienceILC/tlsc-dsfb26v-20_workflows/main/data/flu_data.csv&quot;, skip = 10) head(flu_data) ## # A tibble: 6 × 30 ## Date Argentina Australia Austria Belgium Bolivia Brazil Bulgaria Canada ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2002-12-29 NA NA NA NA NA 174 NA NA ## 2 2003-01-05 NA NA NA NA NA 162 NA NA ## 3 2003-01-12 NA NA NA NA NA 174 NA NA ## 4 2003-01-19 NA NA NA NA NA 162 NA NA ## 5 2003-01-26 NA NA NA NA NA 131 NA NA ## 6 2003-02-02 136 NA NA NA NA 151 NA NA ## # ℹ 21 more variables: Chile &lt;dbl&gt;, France &lt;dbl&gt;, Germany &lt;dbl&gt;, Hungary &lt;dbl&gt;, ## # Japan &lt;dbl&gt;, Mexico &lt;dbl&gt;, Netherlands &lt;dbl&gt;, `New Zealand` &lt;dbl&gt;, ## # Norway &lt;dbl&gt;, Paraguay &lt;dbl&gt;, Peru &lt;dbl&gt;, Poland &lt;dbl&gt;, Romania &lt;dbl&gt;, ## # Russia &lt;dbl&gt;, `South Africa` &lt;dbl&gt;, Spain &lt;dbl&gt;, Sweden &lt;dbl&gt;, ## # Switzerland &lt;dbl&gt;, Ukraine &lt;dbl&gt;, `United States` &lt;dbl&gt;, Uruguay &lt;dbl&gt; dengue_data &lt;- read_csv(&quot;https://raw.githubusercontent.com/DataScienceILC/tlsc-dsfb26v-20_workflows/main/data/dengue_data.csv&quot;, skip = 10) head(dengue_data) ## # A tibble: 6 × 11 ## Date Argentina Bolivia Brazil India Indonesia Mexico Philippines ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2002-12-29 NA 0.101 0.073 0.062 0.101 NA NA ## 2 2003-01-05 NA 0.143 0.098 0.047 0.039 NA NA ## 3 2003-01-12 NA 0.176 0.119 0.051 0.059 0.071 NA ## 4 2003-01-19 NA 0.173 0.17 0.032 0.039 0.052 NA ## 5 2003-01-26 NA 0.146 0.138 0.04 0.112 0.048 NA ## 6 2003-02-02 NA 0.16 0.202 0.038 0.049 0.041 NA ## # ℹ 3 more variables: Singapore &lt;dbl&gt;, Thailand &lt;dbl&gt;, Venezuela &lt;dbl&gt; gap_data&lt;- gapminder head(gap_data) ## country year infant_mortality life_expectancy fertility ## 1 Albania 1960 115.40 62.87 6.19 ## 2 Algeria 1960 148.20 47.50 7.65 ## 3 Angola 1960 208.00 35.98 7.32 ## 4 Antigua and Barbuda 1960 NA 62.97 4.43 ## 5 Argentina 1960 59.87 65.39 3.11 ## 6 Armenia 1960 NA 66.86 4.55 ## population gdp continent region ## 1 1636054 NA Europe Southern Europe ## 2 11124892 13828152297 Africa Northern Africa ## 3 5270844 NA Africa Middle Africa ## 4 54681 NA Americas Caribbean ## 5 20619075 108322326649 Americas South America ## 6 1867396 NA Asia Western Asia after inspecting the data I made the flu and dengue data tidy and alterd the data so it will be easier to merge with the Gapminder data late on. #make flu_data tidy flu_data_tidy&lt;- pivot_longer(data = flu_data, cols = -c(&#39;Date&#39;), names_to = &quot;country&quot;, values_to = &quot;flu_searches&quot;) # remove month and day from Date flu_data_tidy$Date&lt;- str_sub(flu_data_tidy$Date, start =1, end = 4) #rename date to year flu_data_tidy&lt;- rename(flu_data_tidy, year = Date) # group by date and country to get all searches of that year in one row flu_data_tidy&lt;- flu_data_tidy %&gt;% group_by(year, country) %&gt;% summarize(flu_searches = sum(flu_searches)) #change NA to 0 searches flu_data_tidy[is.na(flu_data_tidy)]&lt;- 0 # now it is good to join with gapminder head(flu_data_tidy) ## # A tibble: 6 × 3 ## # Groups: year [1] ## year country flu_searches ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2002 Argentina 0 ## 2 2002 Australia 0 ## 3 2002 Austria 0 ## 4 2002 Belgium 0 ## 5 2002 Bolivia 0 ## 6 2002 Brazil 174 #make dengue_data tidy dengue_data_tidy&lt;- pivot_longer(data = dengue_data, cols = -c(&#39;Date&#39;), names_to = &quot;country&quot;, values_to = &quot;dengue_searches&quot;) # remove month and day from Date dengue_data_tidy$Date&lt;- str_sub(dengue_data_tidy$Date, start =1, end = 4) #rename date to year dengue_data_tidy&lt;- rename(dengue_data_tidy, year = Date) # group by date and country to get all searches of that year in one row dengue_data_tidy&lt;- dengue_data_tidy %&gt;% group_by(year, country) %&gt;% summarize(dengue_searches = sum(dengue_searches)) #change NA to 0 searches dengue_data_tidy[is.na(dengue_data_tidy)]&lt;- 0 # now it can be joined with gapminder and flu_data head(dengue_data_tidy) ## # A tibble: 6 × 3 ## # Groups: year [1] ## year country dengue_searches ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2002 Argentina 0 ## 2 2002 Bolivia 0.101 ## 3 2002 Brazil 0.073 ## 4 2002 India 0.062 ## 5 2002 Indonesia 0.101 ## 6 2002 Mexico 0 After making both the flu data and dengue data tidy, I fixed the variables in terms of data type, class and values. I changed these datasets so that the data type, class and values are the same as the Gapminder data to avoid problems in merging later on #fixing variables so they match with each other and coincide in terms of data type, class and values #flu_data flu_data_tidy&lt;- as.data.frame(flu_data_tidy) %&gt;% convert(int(year)) flu_data_tidy$country&lt;- as.factor(flu_data_tidy$country) head(flu_data_tidy) ## year country flu_searches ## 1 2002 Argentina 0 ## 2 2002 Australia 0 ## 3 2002 Austria 0 ## 4 2002 Belgium 0 ## 5 2002 Bolivia 0 ## 6 2002 Brazil 174 #dengue_data dengue_data_tidy &lt;- as.data.frame(dengue_data_tidy) %&gt;% convert(int(year)) dengue_data_tidy$country&lt;- as.factor(dengue_data_tidy$country) head(dengue_data_tidy) ## year country dengue_searches ## 1 2002 Argentina 0.000 ## 2 2002 Bolivia 0.101 ## 3 2002 Brazil 0.073 ## 4 2002 India 0.062 ## 5 2002 Indonesia 0.101 ## 6 2002 Mexico 0.000 After I finised fixing al the datasets I stored as both csv and rds with the following code #store data as csv and rds #flu data write.csv(flu_data_tidy, &quot;data\\\\flu_data_tidy.csv&quot;, row.names=FALSE) saveRDS(flu_data_tidy, file = &quot;data/flu_data_tidy.rds&quot;) #dengue data write.csv(dengue_data_tidy, &quot;data\\\\dengue_data_tidy.csv&quot;, row.names=FALSE) saveRDS(dengue_data_tidy, file = &quot;data/dengue_data_tidy.rds&quot;) #gapminder data write.csv(gap_data, &quot;data\\\\gap_data.csv&quot;, row.names=FALSE) saveRDS(gap_data, file = &quot;data/gap_data.rds&quot;) The next step was to setup a database in DBeaver. I called the database workflowsdb. ## Using SQL Using RPostgreSQL, I inserted the datasets from earlier in the workflowsdb dataset con dbWriteTable(con, &quot;flu_data_tidy&quot;, flu_data_tidy, overwrite = TRUE) dbWriteTable(con, &quot;dengue_data_tidy&quot;, dengue_data_tidy, overwrite = TRUE) dbWriteTable(con, &quot;gap_data&quot;, gap_data, overwrite = TRUE) In DBeaver I inspected the data again to see if everthing was oke and all datasets where present. I added a screenshot of my DBeaver program, showing SQL code (upper right corner) and a preview of the flu data (bottom right corner) Figure 8.1: Fig. 1: inspecting the contents of the tables with SQL in DBeaver I also inspected the data using R with the Head() function as seen below flu_data_tidy %&gt;% head() ## year country flu_searches ## 1 2002 Argentina 0 ## 2 2002 Australia 0 ## 3 2002 Austria 0 ## 4 2002 Belgium 0 ## 5 2002 Bolivia 0 ## 6 2002 Brazil 174 dengue_data_tidy %&gt;% head() ## year country dengue_searches ## 1 2002 Argentina 0.000 ## 2 2002 Bolivia 0.101 ## 3 2002 Brazil 0.073 ## 4 2002 India 0.062 ## 5 2002 Indonesia 0.101 ## 6 2002 Mexico 0.000 gap_data %&gt;% head() ## country year infant_mortality life_expectancy fertility ## 1 Albania 1960 115.40 62.87 6.19 ## 2 Algeria 1960 148.20 47.50 7.65 ## 3 Angola 1960 208.00 35.98 7.32 ## 4 Antigua and Barbuda 1960 NA 62.97 4.43 ## 5 Argentina 1960 59.87 65.39 3.11 ## 6 Armenia 1960 NA 66.86 4.55 ## population gdp continent region ## 1 1636054 NA Europe Southern Europe ## 2 11124892 13828152297 Africa Northern Africa ## 3 5270844 NA Africa Middle Africa ## 4 54681 NA Americas Caribbean ## 5 20619075 108322326649 Americas South America ## 6 1867396 NA Asia Western Asia Because of the changes I made in the flu data and dangue data in beginning. I could easily merge the data of both flu and dengue to the gapminder data. I used inner join so that if there is not a match between the country,year and flu/dengue searches it is removed from the table. I called the merged dataset “results” This is seen in the image below Figure 8.2: Fig. 2: inspecting the contents of the tables with SQL in DBeaver 8.2 inspecting merged data I loaded the joined data in with the following code: results &lt;- dbReadTable(con, &quot;results&quot;) head(results) ## # A tibble: 6 × 11 ## country year infant_mortality life_expectancy fertility population gdp ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Argentina 2015 11.1 76.5 2.15 43416755 NA ## 2 Bolivia 2015 30.6 73.2 3.14 10724705 NA ## 3 Brazil 2015 14.6 74.4 1.78 207847528 NA ## 4 Mexico 2015 11.3 75.9 2.13 127017224 NA ## 5 Argentina 2014 11.5 76.3 2.16 42980026 NA ## 6 Bolivia 2014 31.7 72.9 3.18 10561887 NA ## # ℹ 4 more variables: continent &lt;chr&gt;, region &lt;chr&gt;, flu_searches &lt;dbl&gt;, ## # dengue_searches &lt;dbl&gt; After reviewing the results data i used summary() to show descriptive statistics. It displays minimum, 1st quartile, median, mean, 3rd quartile, and maximum values for numeric variables, and counts for factors. # Summary statistics summary(results) ## country year infant_mortality life_expectancy ## Length:56 Min. :2002 Min. :11.10 Min. :68.70 ## Class :character 1st Qu.:2005 1st Qu.:14.25 1st Qu.:72.40 ## Mode :character Median :2008 Median :16.10 Median :74.35 ## Mean :2008 Mean :21.64 Mean :73.83 ## 3rd Qu.:2012 3rd Qu.:25.88 3rd Qu.:75.40 ## Max. :2015 Max. :53.70 Max. :76.50 ## ## fertility population gdp continent ## Min. :1.780 Min. : 8653343 Min. :8.752e+09 Length:56 ## 1st Qu.:2.158 1st Qu.: 31098258 1st Qu.:1.848e+11 Class :character ## Median :2.265 Median : 74497526 Median :5.291e+11 Mode :character ## Mean :2.505 Mean : 90395962 Mean :4.538e+11 ## 3rd Qu.:2.712 3rd Qu.:140524316 3rd Qu.:6.943e+11 ## Max. :3.980 Max. :207847528 Max. :9.446e+11 ## NA&#39;s :16 ## region flu_searches dengue_searches ## Length:56 Min. : 0 Min. : 0.000 ## Class :character 1st Qu.: 7041 1st Qu.: 1.464 ## Mode :character Median :10151 Median : 3.889 ## Mean :19459 Mean : 4.644 ## 3rd Qu.:19816 3rd Qu.: 7.713 ## Max. :70979 Max. :16.739 ## 8.3 visualization At last I made various ggplots to visualize data from the joined dataset The first two ggplot are the basic ggplot showing the flu and dengue searches over the year library(ggplot2) library(ggbreak) library(gganimate) library(viridis) results %&gt;% ggplot(aes(x = year, y = flu_searches)) + geom_line(aes(colour = country))+ labs(title = &quot;Flu searches over the years per country&quot;, y = &quot;flu searches&quot;, x = &quot;year&quot;) results %&gt;% ggplot(aes(x = year, y = dengue_searches)) + geom_line(aes(colour = country)) + labs(title = &quot;dengue searches over the years per country&quot;, y = &quot;dengue searches&quot;, x = &quot;year&quot;) Next I joined the ggplots to become one with the following code: results_tidy&lt;- results %&gt;% rename( flu = flu_searches, dengue = dengue_searches ) results_tidy&lt;- pivot_longer(data = results_tidy, cols = c(&#39;flu&#39;, &#39;dengue&#39;), names_to = &quot;disease&quot;, values_to = &quot;searches&quot;) results_tidy ## # A tibble: 112 × 11 ## country year infant_mortality life_expectancy fertility population gdp ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Argentina 2015 11.1 76.5 2.15 43416755 NA ## 2 Argentina 2015 11.1 76.5 2.15 43416755 NA ## 3 Bolivia 2015 30.6 73.2 3.14 10724705 NA ## 4 Bolivia 2015 30.6 73.2 3.14 10724705 NA ## 5 Brazil 2015 14.6 74.4 1.78 207847528 NA ## 6 Brazil 2015 14.6 74.4 1.78 207847528 NA ## 7 Mexico 2015 11.3 75.9 2.13 127017224 NA ## 8 Mexico 2015 11.3 75.9 2.13 127017224 NA ## 9 Argentina 2014 11.5 76.3 2.16 42980026 NA ## 10 Argentina 2014 11.5 76.3 2.16 42980026 NA ## # ℹ 102 more rows ## # ℹ 4 more variables: continent &lt;chr&gt;, region &lt;chr&gt;, disease &lt;chr&gt;, ## # searches &lt;dbl&gt; ggplot(data=results_tidy, aes(x=year, y=log10(searches), color=country, shape = disease)) + geom_line() + geom_point()+ ylim(0.0, 5) I also made a ggplot showing the relation between the population of mexico and flu searches on google mexico &lt;-results %&gt;% filter(country == &quot;Mexico&quot;) cor_coefficient_mex&lt;- round(cor.test(mexico$population, mexico$flu_searches, method=c(&quot;pearson&quot;))$estimate,1) mexico %&gt;% ggplot(aes(x = population, y = flu_searches)) + geom_point(aes(colour = &quot;red&quot;), show.legend = FALSE) + labs(title = &quot;Relation between the population of mexico \\nand flu searches on google&quot;, y = &quot;flu searches&quot;, x = &quot;population&quot;) + annotate(&quot;text&quot;, x = 108000000, y = 65000, size=4, label = paste(&quot;pearson&#39;s r = &quot;, cor_coefficient_mex)) and i made this ggplot showing Relation between the population of Brazil and dengue searches on google Brazil &lt;-results %&gt;% filter(country == &quot;Brazil&quot;) cor_coefficient_brazil&lt;- round(cor.test(Brazil$population, Brazil$dengue_searches, method=c(&quot;pearson&quot;))$estimate,1) Brazil %&gt;% ggplot(aes(x = population, y = dengue_searches)) + geom_point(aes(colour = &quot;blue&quot;), show.legend = FALSE) + labs(title = &quot;Relation between the population of Brazil \\nand dengue searches on google&quot;, y = &quot;flu searches&quot;, x = &quot;population&quot;) + annotate(&quot;text&quot;, x = 200000000, y = 15, size=4, label = paste(&quot;pearson&#39;s r = &quot;, cor_coefficient_mex)) "],["building-a-package.html", "9 building a package 9.1 dataInspecter", " 9 building a package This exercise is about building a package. The package should at least include: A properly formatted DESCRIPTION file, with all the fields including relevant information (so change the default values) 4 different functions that I wrote and with proper documentation, using roxygen2 comments A NAMESPACE file, generated with the command devtools::document() 1 Raw dataset that is documented and cleaned into a clean dataset. This clean dataset should be accessible inside your package. call data(“tetracyclines_usage”, package = “dataInspecter”) to load the cleaned dataset of interest in the Global Environment. One vignette that is accessible via the command browseVignettes(“dataInspecter”) or vignette(“dataInspecter”) The package installs from Github without errors when runing: devtools::install_github(“kjettil/dataInspecter”) 9.1 dataInspecter The package I made is called “dataInspecter”. It contains four functions with examples, a dataset and a vignette. 9.1.1 Functions dataInspecter contains four functions that can be helpful for loading, inspecting and saving data. The four functions are: 1: read_data_from_excel() -&gt; loads in data from excel and previews data 2: print_head() -&gt; shows the first 10 rows of the dataset 3: save_datafile() -&gt; saves variable as .csv and .rds 4: time() -&gt; tells the time 9.1.2 Installation You can install the development version of dataInspecter with vignette from GitHub with: # install.packages(&quot;devtools&quot;) devtools::install_github(&quot;kjettil/dataInspecter&quot;, build_vignettes = TRUE) 9.1.3 Data This package comes with a dataset that shows the tetracyclines consumption in the EU/EEA from 2011 till 2020. ?tetracyclines_usage will give you more detailed information about the dataset. "],["citations-using-zotero.html", "10 Citations using Zotero 10.1 introduction 10.2 references", " 10 Citations using Zotero In this exercise I wrote an introduction for my project using the Zotero citation tool. 10.1 introduction Skeletal muscle mass is the result of a balance between protein synthesis and protein breakdown of skeletal muscle proteins. A decreased protein synthesis response or anabolic resistance to anabolic stimuli in elderly can lead to loss of skeletal muscle mass. This can be seen in people with sarcopenia. Sarcopenia is the result of multiple factors, including lack of activity/exercise, increased levels of oxidative stress, endocrine changes, lack of nutrition and as said before a decreased protein synthesis response or anabolic resistance. Boirie and Guillet (2018); Van Dijk et al. (2016) Muscle maintenance depends on amino acids. One of the amino acids that produces a high anabolic stimulus is leucine. This is because leucine has the ability to activate mammalian target of rapamycin complex 1 (mTORC1). mTORC1 is a protein complex that controls protein synthesis and is active in the translation of proteins. The activation of mTORC1 leads to the activation of both p70s6k kinase and the 4E-BP1 protein. These are important because both factors are involved in mRNA translation initiation and muscle protein synthesis (MPS). Dijk et al. (2018) Studies have shown that MPS in skeletal muscle in young rats, after taking a single dosis leucine orally, is stimulated. The articles (Dardevet et al. 2000; Crozier et al. 2005) also show that amino acids and leucine stimulate muscle protein synthesis and that aging is associated with a decrease in this effect. In this experiment they tested the effects of amino acids or leucine alone. This was assessed in vitro on epitrochlearis muscle from young, adult and old rats. The aim of this study was to investigate the effect of leucine alone or in the presence of whey protein on MPS and the activation of the mTORC1 signaling pathway in elderly mice. To determine the relevance of leucine and other amino acids, the free amino acid content in plasma and muscle was determined. Our task in this project is to write a code in R that visualizes the free amino acid content in plasma. The visualizations should clearly show the effects on the free amino acids after adding leucine and other factors. We will create graphs like a boxplot, but we will also be using heatmaps. In a heatmap, each row and column of the matrix represents a variable or an observation, and The cells within the matrix represent the values of those variables or observations. The color of each cell represents the magnitude or intensity of the value. Typically, a color scale is used to map the values to different colors, with higher values represented by brighter or darker colors and lower values represented by lighter or cooler colors. Heatmaps are particularly useful for identifying patterns, trends, and clusters within the data. In this case the heatmap will cluster the different treated groups in the experiment. At last we will be looking into correlations of the amino acids and visualize this using the corrplot package. After creating the visualizations we automate the code (Parameterized rmarkdown or using functions) so that the employer can easily use the code and only have to load the correct dataset in the code. 10.2 references "]]
